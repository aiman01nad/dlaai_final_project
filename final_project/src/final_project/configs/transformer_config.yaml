model: 
  num_embeddings: 10
  seq_len: 64
  embedding_dim: 128
  nheads: 4
  num_layers: 4
  feedforward_dim: 256
  dropout: 0.1

training:
  batch_size: 64
  epochs: 10
  learning_rate: 1e-3
